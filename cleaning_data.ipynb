{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\h'\n",
      "C:\\Users\\Soumya Pandey\\AppData\\Local\\Temp\\ipykernel_39336\\404873728.py:2: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  file_path = \"processed_data\\hourly_event_attendance.csv\"  # Update this if needed\n",
      "C:\\Users\\Soumya Pandey\\AppData\\Local\\Temp\\ipykernel_39336\\404873728.py:6: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['Hour'] = pd.to_datetime(df['Hour']).dt.floor('H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved at: cleaned_hourly_event_attendance.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "file_path = \"processed_data\\hourly_event_attendance.csv\"  # Update this if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'Hour' column to a uniform datetime format (keeping only hour-level precision)\n",
    "df['Hour'] = pd.to_datetime(df['Hour']).dt.floor('H')\n",
    "\n",
    "# Remove duplicate rows\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# Save the cleaned dataset to a local directory\n",
    "cleaned_file_path = \"cleaned_hourly_event_attendance.csv\"  # Change the path as needed\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved at: {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumya Pandey\\AppData\\Local\\Temp\\ipykernel_39336\\2110915090.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df2_hourly = df2.resample('H').mean()\n"
     ]
    }
   ],
   "source": [
    "file_path = \"weather_energy.csv\"\n",
    "df2 = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "df2.head()\n",
    "\n",
    "# Convert datetime column to pandas datetime format\n",
    "df2['datetime'] = pd.to_datetime(df2['datetime'])\n",
    "\n",
    "# Set datetime as index\n",
    "df2.set_index('datetime', inplace=True)\n",
    "\n",
    "# Aggregate data to hourly intervals by taking the mean\n",
    "df2_hourly = df2.resample('H').mean()\n",
    "\n",
    "# Reset index to make datetime a column again\n",
    "df2_hourly.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Power demand</th>\n",
       "      <th>temp</th>\n",
       "      <th>dwpt</th>\n",
       "      <th>rhum</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>moving_avg_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1975.541667</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.90</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>1976.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 01:00:00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1805.590000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.90</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1822.649167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 02:00:00</td>\n",
       "      <td>23.5</td>\n",
       "      <td>1665.914167</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.25</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018.05</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1675.064722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 03:00:00</td>\n",
       "      <td>35.5</td>\n",
       "      <td>1607.331667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>95.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018.05</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1608.205278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 04:00:00</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1676.528333</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.50</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1664.828333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  Unnamed: 0  Power demand  temp  dwpt   rhum  wdir  \\\n",
       "0 2021-01-01 00:00:00         2.5   1975.541667   8.0  6.90   93.0   0.0   \n",
       "1 2021-01-01 01:00:00        11.5   1805.590000   8.0  6.90   93.0   0.0   \n",
       "2 2021-01-01 02:00:00        23.5   1665.914167   7.5  6.25   92.0   0.0   \n",
       "3 2021-01-01 03:00:00        35.5   1607.331667   7.0  6.30   95.5   0.0   \n",
       "4 2021-01-01 04:00:00        47.5   1676.528333   6.5  6.50  100.0   0.0   \n",
       "\n",
       "   wspd     pres    year  month  day  hour  minute  moving_avg_3  \n",
       "0   0.0  1017.00  2021.0    1.0  1.0   0.0    42.5   1976.777500  \n",
       "1   0.0  1017.00  2021.0    1.0  1.0   1.0    27.5   1822.649167  \n",
       "2   0.0  1018.05  2021.0    1.0  1.0   2.0    27.5   1675.064722  \n",
       "3   0.0  1018.05  2021.0    1.0  1.0   3.0    27.5   1608.205278  \n",
       "4   0.0  1017.00  2021.0    1.0  1.0   4.0    27.5   1664.828333  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the aggregated data\n",
    "df2_hourly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved at: aggregated_weather.csv\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path2 = \"aggregated_weather.csv\"  # Change the path as needed\n",
    "df2_hourly.to_csv(cleaned_file_path2, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved at: {cleaned_file_path2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Pearson correlation: -0.0052\n",
      "\n",
      "Event Type Correlations (sorted from max to min absolute correlation):\n",
      "Protest & Demonstration: -0.0474\n",
      "Religious Event: -0.0244\n",
      "Public Gathering: -0.0130\n",
      "Sports & Competition: -0.0054\n",
      "Cultural & Tourism Event: -0.0052\n",
      "Other: -0.0010\n",
      "\n",
      "Event with highest correlation: Protest & Demonstration (-0.0474)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumya Pandey\\AppData\\Local\\Temp\\ipykernel_39336\\2278790158.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  weather_hourly = weather_df.resample('H', on='datetime').mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "weather_df = pd.read_csv('aggregated_weather.csv')\n",
    "hourly_df = pd.read_csv('cleaned_hourly_event_attendance.csv')\n",
    "\n",
    "# Convert datetime columns to pandas datetime format\n",
    "weather_df['datetime'] = pd.to_datetime(weather_df['datetime'])\n",
    "hourly_df['datetime'] = pd.to_datetime(hourly_df['Hour'])\n",
    "\n",
    "# Resample weather data to hourly by averaging every 15-minute intervals\n",
    "weather_hourly = weather_df.resample('H', on='datetime').mean().reset_index()\n",
    "\n",
    "# Merge both datasets on 'datetime'\n",
    "merged_df = pd.merge(hourly_df, weather_hourly, on='datetime', how='inner')\n",
    "\n",
    "# Check for NaNs and Infinite values\n",
    "merged_df = merged_df.replace([np.inf, -np.inf], np.nan).dropna(subset=['Power demand', 'Estimated_Attendance'])\n",
    "\n",
    "# Compute overall Pearson correlation\n",
    "if len(merged_df) > 1:\n",
    "    overall_corr, _ = pearsonr(merged_df['Power demand'], merged_df['Estimated_Attendance'])\n",
    "    print(f\"Overall Pearson correlation: {overall_corr:.4f}\")\n",
    "else:\n",
    "    print(\"Not enough data after cleaning to compute correlation.\")\n",
    "\n",
    "# Group by event_type and compute correlation for each\n",
    "event_correlations = {}\n",
    "for event, group in merged_df.groupby('EventCategory'):\n",
    "    if len(group) > 1:  # Ensure enough data points for correlation\n",
    "        try:\n",
    "            event_corr, _ = pearsonr(group['Power demand'], group['Estimated_Attendance'])\n",
    "            event_correlations[event] = event_corr\n",
    "        except ValueError:\n",
    "            continue  # Skip event types with insufficient valid data\n",
    "\n",
    "# Sort events by absolute correlation (strongest first)\n",
    "sorted_events = sorted(event_correlations.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print the sorted event categories and their correlation\n",
    "print(\"\\nEvent Type Correlations (sorted from max to min absolute correlation):\")\n",
    "for event, correlation in sorted_events:\n",
    "    print(f\"{event}: {correlation:.4f}\")\n",
    "\n",
    "# Find the event with the highest correlation\n",
    "if sorted_events:\n",
    "    most_correlated_event, highest_corr = sorted_events[0]\n",
    "    print(f\"\\nEvent with highest correlation: {most_correlated_event} ({highest_corr:.4f})\")\n",
    "else:\n",
    "    print(\"\\nNo valid event correlations found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

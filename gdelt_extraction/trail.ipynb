{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumya Pandey\\AppData\\Local\\Temp\\ipykernel_27900\\707627114.py:23: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to fetch data for 20250307093434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307091934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307090434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307084934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307083434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307081934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307080434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307074934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307073434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307071934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307070434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307064934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307063434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307061934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307060434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307054934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307053434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307051934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307050434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307044934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307043434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307041934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307040434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307034934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307033434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307031934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307030434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307024934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307023434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307021934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307020434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307014934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307013434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307011934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307010434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307004934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307003434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307001934: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250307000434: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 20250306234934: HTTP Error 404: Not Found\n",
      "❌ No data retrieved.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# GDELT Base URL for raw CSV files\n",
    "GDELT_BASE_URL = \"http://data.gdeltproject.org/gdeltv2/\"\n",
    "\n",
    "# Columns from GDELT Event Codebook\n",
    "EVENT_COLUMNS = [\n",
    "    \"GlobalEventID\", \"Day\", \"MonthYear\", \"Year\", \"FractionDate\", \n",
    "    \"Actor1Code\", \"IsRootEvent\", \"EventCode\", \"EventBaseCode\", \"EventRootCode\", \"QuadClass\", \"GoldsteinScale\", \n",
    "    \"NumMentions\", \"NumSources\", \"NumArticles\", \"AvgTone\", \"ActionGeo_Type\", \"ActionGeo_Fullname\", \"ActionGeo_CountryCode\", \"ActionGeo_ADM1Code\", \n",
    "    \"ActionGeo_ADM2Code\", \"ActionGeo_Lat\", \"ActionGeo_Long\", \"ActionGeo_FeatureID\", \n",
    "    \"DATEADDED\", \"SOURCEURL\"\n",
    "]\n",
    "\n",
    "def generate_past_intervals(hours=10, interval_minutes=15):\n",
    "    \"\"\"\n",
    "    Generate a list of timestamps for the past 'hours' with a given interval (in minutes).\n",
    "    GDELT timestamps are in UTC and use YYYYMMDDHHMMSS format.\n",
    "    \"\"\"\n",
    "    timestamps = []\n",
    "    now = datetime.utcnow()\n",
    "    for i in range(0, hours * 60, interval_minutes):\n",
    "        timestamp = now - timedelta(minutes=i)\n",
    "        timestamps.append(timestamp.strftime(\"%Y%m%d%H%M%S\"))\n",
    "    return timestamps\n",
    "\n",
    "def fetch_gdelt_data(timestamp):\n",
    "    \"\"\"Fetches GDELT data for a specific timestamp.\"\"\"\n",
    "    csv_url = f\"{GDELT_BASE_URL}export.{timestamp}.csv\"\n",
    "    try:\n",
    "        data = pd.read_csv(csv_url, sep=\"\\t\", names=EVENT_COLUMNS, encoding=\"latin1\", low_memory=False)\n",
    "        print(f\"✅ Fetched data for {timestamp}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to fetch data for {timestamp}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fetches GDELT data for the past 10 hours at 15-minute intervals.\"\"\"\n",
    "    timestamps = generate_past_intervals(hours=10, interval_minutes=15)\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for timestamp in timestamps:\n",
    "        data = fetch_gdelt_data(timestamp)\n",
    "        if data is not None:\n",
    "            all_data.append(data)\n",
    "    \n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        filename = f\"gdelt_events_past10hours_{datetime.utcnow().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "        final_df.to_csv(filename, index=False)\n",
    "        print(f\"✅ Data saved as {filename}\")\n",
    "    else:\n",
    "        print(\"❌ No data retrieved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumya Pandey\\AppData\\Local\\Temp\\ipykernel_27900\\3427347551.py:23: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to fetch data for 202503070900: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070900: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070900: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070800: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070800: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070800: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070800: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070700: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070700: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070700: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070700: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070600: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070600: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070600: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070600: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070500: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070500: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070500: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070500: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070400: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070400: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070400: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070400: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070300: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070300: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070300: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070300: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070200: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070200: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070200: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070200: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070100: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070100: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070100: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070100: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070000: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070000: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070000: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503070000: HTTP Error 404: Not Found\n",
      "❌ Failed to fetch data for 202503062300: HTTP Error 404: Not Found\n",
      "❌ No data retrieved for any interval.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# GDELT Base URL for raw CSV files\n",
    "GDELT_BASE_URL = \"http://data.gdeltproject.org/gdeltv2/\"\n",
    "\n",
    "# Columns from GDELT Event Codebook\n",
    "EVENT_COLUMNS = [\n",
    "    \"GlobalEventID\", \"Day\", \"MonthYear\", \"Year\", \"FractionDate\", \n",
    "    \"Actor1Code\", \"IsRootEvent\", \"EventCode\", \"EventBaseCode\", \"EventRootCode\", \"QuadClass\", \"GoldsteinScale\", \n",
    "    \"NumMentions\", \"NumSources\", \"NumArticles\", \"AvgTone\", \"ActionGeo_Type\", \"ActionGeo_Fullname\", \"ActionGeo_CountryCode\", \"ActionGeo_ADM1Code\", \n",
    "    \"ActionGeo_ADM2Code\", \"ActionGeo_Lat\", \"ActionGeo_Long\", \"ActionGeo_FeatureID\", \n",
    "    \"DATEADDED\", \"SOURCEURL\"\n",
    "]\n",
    "\n",
    "def generate_past_intervals(hours=10):\n",
    "    \"\"\"\n",
    "    Generate timestamps for the past 'hours' at 15-minute intervals\n",
    "    ensuring format YYYYMMDDHHMM00 (minutes = 00, 15, 30, or 45).\n",
    "    \"\"\"\n",
    "    timestamps = []\n",
    "    now = datetime.utcnow()\n",
    "    \n",
    "    for i in range(hours * 4):  # 4 intervals per hour (every 15 min)\n",
    "        timestamp = now - timedelta(minutes=i * 15)\n",
    "        formatted_timestamp = timestamp.strftime(\"%Y%m%d%H%M\")\n",
    "        formatted_timestamp = formatted_timestamp[:-2] + \"00\"  # Set seconds to \"00\"\n",
    "        timestamps.append(formatted_timestamp)\n",
    "    \n",
    "    return timestamps\n",
    "\n",
    "def fetch_gdelt_data(timestamp):\n",
    "    \"\"\"Fetches GDELT data for a specific timestamp and handles errors.\"\"\"\n",
    "    csv_url = f\"{GDELT_BASE_URL}export.{timestamp}.csv\"\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(csv_url, sep=\"\\t\", names=EVENT_COLUMNS, encoding=\"latin1\", low_memory=False)\n",
    "        print(f\"✅ Successfully fetched data for {timestamp}\")\n",
    "        return data\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"❌ HTTP Error for {timestamp}: {http_err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to fetch data for {timestamp}: {e}\")\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fetches GDELT data for the past 10 hours at 15-minute intervals.\"\"\"\n",
    "    timestamps = generate_past_intervals(hours=10)\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for timestamp in timestamps:\n",
    "        data = fetch_gdelt_data(timestamp)\n",
    "        if data is not None and not data.empty:\n",
    "            all_data.append(data)\n",
    "    \n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        filename = f\"gdelt_events_past10hours_{datetime.utcnow().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "        final_df.to_csv(filename, index=False)\n",
    "        print(f\"✅ Data saved as {filename}\")\n",
    "    else:\n",
    "        print(\"❌ No data retrieved for any interval.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully fetched data from http://data.gdeltproject.org/gdeltv2/20250307094500.export.CSV.zip\n",
      "✅ Data saved as gdelt_events_past10hours_20250307_0939.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumya Pandey\\AppData\\Local\\Temp\\ipykernel_27900\\4206594582.py:60: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  filename = f\"gdelt_events_past10hours_{datetime.utcnow().strftime('%Y%m%d_%H%M')}.csv\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# GDELT last update URL\n",
    "LAST_UPDATE_URL = \"http://data.gdeltproject.org/gdeltv2/lastupdate.txt\"\n",
    "\n",
    "# Columns from GDELT Event Codebook\n",
    "EVENT_COLUMNS = [\n",
    "    \"GlobalEventID\", \"Day\", \"MonthYear\", \"Year\", \"FractionDate\", \n",
    "    \"Actor1Code\", \"IsRootEvent\", \"EventCode\", \"EventBaseCode\", \"EventRootCode\", \"QuadClass\", \"GoldsteinScale\", \n",
    "    \"NumMentions\", \"NumSources\", \"NumArticles\", \"AvgTone\", \"ActionGeo_Type\", \"ActionGeo_Fullname\", \"ActionGeo_CountryCode\", \"ActionGeo_ADM1Code\", \n",
    "    \"ActionGeo_ADM2Code\", \"ActionGeo_Lat\", \"ActionGeo_Long\", \"ActionGeo_FeatureID\", \n",
    "    \"DATEADDED\", \"SOURCEURL\"\n",
    "]\n",
    "\n",
    "def fetch_available_gdelt_files():\n",
    "    \"\"\"\n",
    "    Fetch the last available GDELT update file URLs.\n",
    "    Returns a list of URLs from the past 10 hours.\n",
    "    \"\"\"\n",
    "    response = requests.get(LAST_UPDATE_URL)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        lines = response.text.strip().split(\"\\n\")\n",
    "        file_urls = []\n",
    "\n",
    "        for line in lines:\n",
    "            if \"export\" in line and \".CSV.zip\" in line:\n",
    "                url = line.split()[-1]  # Extract file URL\n",
    "                file_urls.append(url)\n",
    "        \n",
    "        return file_urls[:40]  # Limit to last 10 hours (each file is ~15 min)\n",
    "    \n",
    "    print(\"❌ Failed to fetch available GDELT update files.\")\n",
    "    return []\n",
    "\n",
    "def fetch_gdelt_data(file_url):\n",
    "    \"\"\"Fetches and extracts GDELT event data from the given URL.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_url, sep=\"\\t\", names=EVENT_COLUMNS, encoding=\"latin1\", low_memory=False)\n",
    "        print(f\"✅ Successfully fetched data from {file_url}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to fetch data from {file_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fetches and combines GDELT data from the last 10 hours.\"\"\"\n",
    "    file_urls = fetch_available_gdelt_files()\n",
    "    all_data = []\n",
    "\n",
    "    for url in file_urls:\n",
    "        data = fetch_gdelt_data(url)\n",
    "        if data is not None and not data.empty:\n",
    "            all_data.append(data)\n",
    "\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        filename = f\"gdelt_events_past10hours_{datetime.utcnow().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "        final_df.to_csv(filename, index=False)\n",
    "        print(f\"✅ Data saved as {filename}\")\n",
    "    else:\n",
    "        print(\"❌ No data retrieved from any available files.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fetched 6 Delhi events from http://data.gdeltproject.org/gdeltv2/20250307100000.export.CSV.zip\n",
      "✅ Data saved as gdelt_delhi_events_past10hours_20250307_0955.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumya Pandey\\AppData\\Local\\Temp\\ipykernel_27900\\2364706960.py:70: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  filename = f\"gdelt_delhi_events_past10hours_{datetime.utcnow().strftime('%Y%m%d_%H%M')}.csv\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# GDELT last update URL\n",
    "LAST_UPDATE_URL = \"http://data.gdeltproject.org/gdeltv2/lastupdate.txt\"\n",
    "\n",
    "# Columns from GDELT Event Codebook\n",
    "# Columns from GDELT Event Codebook\n",
    "EVENT_COLUMNS = [\n",
    "    \"GlobalEventID\", \"Day\", \"MonthYear\", \"Year\", \"FractionDate\", \n",
    "    \"Actor1Code\", \"IsRootEvent\", \"EventCode\", \"EventBaseCode\", \"EventRootCode\", \"QuadClass\", \"GoldsteinScale\", \n",
    "    \"NumMentions\", \"NumSources\", \"NumArticles\", \"AvgTone\", \"ActionGeo_Type\", \"ActionGeo_Fullname\", \"ActionGeo_CountryCode\", \"ActionGeo_ADM1Code\", \n",
    "    \"ActionGeo_ADM2Code\", \"ActionGeo_Lat\", \"ActionGeo_Long\", \"ActionGeo_FeatureID\", \n",
    "    \"DATEADDED\", \"SOURCEURL\"\n",
    "]\n",
    "\n",
    "def fetch_available_gdelt_files():\n",
    "    \"\"\"\n",
    "    Fetch the last available GDELT update file URLs.\n",
    "    Returns a list of URLs from the past 10 hours.\n",
    "    \"\"\"\n",
    "    response = requests.get(LAST_UPDATE_URL)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        lines = response.text.strip().split(\"\\n\")\n",
    "        file_urls = []\n",
    "\n",
    "        for line in lines:\n",
    "            if \"export\" in line and \".CSV.zip\" in line:\n",
    "                url = line.split()[-1]  # Extract file URL\n",
    "                file_urls.append(url)\n",
    "        \n",
    "        return file_urls[:40]  # Limit to last 10 hours (each file is ~15 min)\n",
    "    \n",
    "    print(\"❌ Failed to fetch available GDELT update files.\")\n",
    "    return []\n",
    "\n",
    "def fetch_gdelt_data(file_url):\n",
    "    \"\"\"Fetches and extracts GDELT event data from the given URL, filtering only for Delhi events.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_url, sep=\"\\t\", names=EVENT_COLUMNS, encoding=\"latin1\", low_memory=False)\n",
    "\n",
    "        # Filter only for events happening in Delhi\n",
    "        delhi_data = data[data[\"ActionGeo_Fullname\"].str.contains(\"Delhi\", na=False, case=False)]\n",
    "\n",
    "        if not delhi_data.empty:\n",
    "            print(f\"✅ Fetched {len(delhi_data)} Delhi events from {file_url}\")\n",
    "            return delhi_data\n",
    "        else:\n",
    "            print(f\"🔍 No Delhi events in {file_url}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to fetch data from {file_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fetches and combines GDELT data for Delhi from the last 10 hours.\"\"\"\n",
    "    file_urls = fetch_available_gdelt_files()\n",
    "    all_data = []\n",
    "\n",
    "    for url in file_urls:\n",
    "        data = fetch_gdelt_data(url)\n",
    "        if data is not None and not data.empty:\n",
    "            all_data.append(data)\n",
    "\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        filename = f\"gdelt_delhi_events_past10hours_{datetime.utcnow().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "        final_df.to_csv(filename, index=False)\n",
    "        print(f\"✅ Data saved as {filename}\")\n",
    "    else:\n",
    "        print(\"❌ No Delhi events retrieved from any available files.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
